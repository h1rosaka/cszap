MAP関数
データを読み込んで、keyとvalueを取得する
keyとvalueにmapする

特定のものkeyのものは一箇所に集めて、reduceで集計
→このkeyのvalueはこれとこれとこれ
    →ここからさらに集計してkeyに対する最終的なvalueを求める

ボトルネックになりがちなIOをなるべく抑えることができる
途中でどれかのマシンが死んでも、チャンクごとに管理しているので、別のマシンで続きを実行できる

使う側としては、map関数とreduce関数を定義するだけ

mapとreduceに変換しないといけない、とも言える。機械学習の特徴量作る処理をその二つに分解しないといけない。

mapとreduceを組み合わせると、任意のことができる。group byをしたいときだけ嬉しい、というわけではない。あくまで主眼は途中で止まっても途中からやり直せたりするのが嬉しい。
会社の優先度の高い別prjが途中でリソース持ってっちゃうとか、故障以外にも途中でとまるケースはある。




p439
データの近くに計算を持っていく
台湾のデータセンターにデータあるのに、アメリカでmapのタスクする、とかはネットワーク無駄なのでしない。もっと小さい粒度だど、同じDC内の同じラックの方がネットワークの距離小さくて良い、とか、なんなら同じマシン内のCPU使えるならそれが最高。


map reduceはjoinに弱い
1回joinすると、1回map reduceしないといけないので、それだけで数分かかる。(空いてるプロセス100台見つけてきます~から始めないといけなかったりでオーバーヘッドが大きい)
    key単位でreducer作って
小さいテーブル(都道府県で47行しかないとか)が10個とかあるとmap reduceだと遅いので、別の方法で先に結合できるなら嬉しい。→map側での結合　p447


p458
Googleみたいに何台もマシンあって、それを
特徴量をsparkで作ってたのは何故なのだろうか、MPPデータベースではダメだった？他にどんな打ち手があっただろうか

BQは裏で、Map Reduceのインメモリ版みたいなことをしてる、何千台ものマシンが裏にいる